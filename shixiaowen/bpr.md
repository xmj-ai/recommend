# 贝叶斯个性化排序(Bayesian Persional Ranking BPR )算法原理及实战
[TOC]
---

## 1、BPR算法简介
## 1.1 基本思路
>在BPR算法中，我们将任意用户u对应的物品进行标记，如果用户u在同时有物品i和j的时候点击了i，那么我们就得到了一个三元组<u,i,j>，它表示对用户u来说，i的排序要比j靠前。如果对于用户u来说我们有m组这样的反馈，那么我们就可以得到m组用户u对应的训练样本。

这里，我们做出两个假设：

- 1.每个用户之间的偏好行为相互独立，即用户u在商品i和j之间的偏好和**其他用户无关**。
- 2.同一用户对不同物品的偏序相互独立，也就是用户u在商品i和j之间的偏好和**其他的商品无关**。

为了便于表述，我们用>u符号表示用户u的偏好，上面的<u,i,j>可以表示为：i >u j。

在BPR中，我们也用到了类似矩阵分解的思想，对于用户集U和物品集I对应的U*I的预测排序矩阵，我们期望得到两个分解后的用户矩阵W(|U|×k)和物品矩阵H(|I|×k)，满足：

$\overline{X}=WH^T$

那么对于任意一个用户u，对应的任意一个物品i，我们预测得出的用户对该物品的偏好计算如下：

$\overline{x}_{ui}=w_u \times h_i=\displaystyle\sum_{f=1}^kw_{uf}h_{if}$

>而模型的最终目标是寻找合适的矩阵W和H，让X-(公式打不出来，这里代表的是X上面有一个横线，即W和H矩阵相乘后的结果)和X(实际的评分矩阵)最相似。看到这里，也许你会说，BPR和矩阵分解没有什区别呀？是的，到目前为止的基本思想是一致的，但是具体的算法运算思路，确实千差万别的，我们慢慢道来。


## 1.2 算法运算思路

BPR 基于最大后验估计P(W,H|>u)来求解模型参数W,H,这里我们用θ来表示参数W和H, >u代表用户u对应的所有商品的全序关系,则优化目标是P(θ|>u)。根据贝叶斯公式，我们有：




## 2、算法实现
## 3、总结


作者：石晓文的学习日记
链接：https://www.jianshu.com/p/ba1936ee0b69
来源：简书
简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。